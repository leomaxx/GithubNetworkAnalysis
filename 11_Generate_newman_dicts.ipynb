{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from copy import deepcopy\n",
    "from itertools import combinations\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/2016_q1_data.pickle', 'rb') as picklefile:\n",
    "    q1d = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def newman_weight(a, b, author_dict, project_dict):\n",
    "    common = author_dict[a].intersection(author_dict[b])\n",
    "    weight = 0\n",
    "    for project in common:\n",
    "        weight += 1.0/(len(project_dict[project])-1)\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_newman_graph(df, mirror = False):\n",
    "    author_dict = collections.defaultdict(set)\n",
    "    project_dict = collections.defaultdict(set)\n",
    "    weight_dict = collections.defaultdict(float)\n",
    "    \n",
    "    edge_seen = set()\n",
    "    \n",
    "    for i in range(df.shape[0]):\n",
    "        project_dict[df.iloc[i,0]].add(df.iloc[i,1])\n",
    "        author_dict[df.iloc[i,1]].add(df.iloc[i,0])\n",
    "        \n",
    "    projects = df['project_id'].unique()\n",
    "    authors = df['author_id'].unique()\n",
    "    \n",
    "    for project in projects:\n",
    "        p_authors = list(project_dict[project])\n",
    "        edges = combinations(p_authors, 2)\n",
    "        for src_id, dst_id in edges:\n",
    "            if src_id > dst_id:\n",
    "                src_id, dst_id = dst_id, src_id\n",
    "            if (src_id, dst_id) not in edge_seen:\n",
    "                weight_dict[(src_id, dst_id)] = newman_weight(src_id, dst_id, author_dict, project_dict)\n",
    "    \n",
    "    weight_dict2 = deepcopy(weight_dict)\n",
    "    if mirror:\n",
    "        for a,b in weight_dict.keys():\n",
    "            weight_dict2[(b,a)] = weight_dict[(a,b)]\n",
    "          \n",
    "    return author_dict, project_dict, weight_dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_dict, project_dict, weight_dict = construct_newman_graph(q1d, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbors(author_dict, project_dict):\n",
    "    i = 0\n",
    "    print ('Total authors to be processed:', len(author_dict.keys()))\n",
    "    print ('------------------------------------')\n",
    "    neighbor_dict = collections.defaultdict(set)\n",
    "    for author in author_dict:\n",
    "        i += 1\n",
    "        if i%10000 == 0:\n",
    "            print ('Processing author', i)\n",
    "        for project in author_dict[author]:\n",
    "            neighbor_dict[author] = neighbor_dict[author].union(project_dict[project])\n",
    "        neighbor_dict[author].remove(author)\n",
    "    return neighbor_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total authors to be processed: 176061\n",
      "------------------------------------\n",
      "Processing author 10000\n",
      "Processing author 20000\n",
      "Processing author 30000\n",
      "Processing author 40000\n",
      "Processing author 50000\n",
      "Processing author 60000\n",
      "Processing author 70000\n",
      "Processing author 80000\n",
      "Processing author 90000\n",
      "Processing author 100000\n",
      "Processing author 110000\n",
      "Processing author 120000\n",
      "Processing author 130000\n",
      "Processing author 140000\n",
      "Processing author 150000\n",
      "Processing author 160000\n",
      "Processing author 170000\n"
     ]
    }
   ],
   "source": [
    "neighbor_dict = get_neighbors(author_dict, project_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./data/2016_q1_newman-weights.pickle', 'wb') as picklefile:\n",
    "    pickle.dump(weight_dict, picklefile)\n",
    "with open('./data/2016_q1_newman-neighbours.pickle', 'wb') as picklefile:\n",
    "    pickle.dump(neighbor_dict, picklefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Graph for 2016 Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./data/2016_q2_data.pickle', 'rb') as picklefile:\n",
    "    q2d = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "author_dict2, project_dict2, weight_dict2 = construct_newman_graph(q2d, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total authors to be processed: 141583\n",
      "------------------------------------\n",
      "Processing author 10000\n",
      "Processing author 20000\n",
      "Processing author 30000\n",
      "Processing author 40000\n",
      "Processing author 50000\n",
      "Processing author 60000\n",
      "Processing author 70000\n",
      "Processing author 80000\n",
      "Processing author 90000\n",
      "Processing author 100000\n",
      "Processing author 110000\n",
      "Processing author 120000\n",
      "Processing author 130000\n",
      "Processing author 140000\n"
     ]
    }
   ],
   "source": [
    "neighbor_dict2 = get_neighbors(author_dict2, project_dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./data/2016_q2_newman-weights.pickle', 'wb') as picklefile:\n",
    "    pickle.dump(weight_dict2, picklefile)\n",
    "with open('./data/2016_q2_newman-neighbours.pickle', 'wb') as picklefile:\n",
    "    pickle.dump(neighbor_dict2, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141583"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(neighbor_dict2.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/2016_q2_newman-neighbours_1.pickle', 'rb') as picklefile:\n",
    "    neighbours_1 = pickle.load(picklefile, encoding='latin1')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141583"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(neighbours_1.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (conda 3.6)",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
