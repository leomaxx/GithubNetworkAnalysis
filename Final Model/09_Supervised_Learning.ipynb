{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, learning_curve\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "% config InlineBackend . figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadfile(path):\n",
    "    with open(path,'rb') as picklefile:\n",
    "        file = pickle.load(picklefile, encoding='latin1')\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_newman_w = loadfile('./data/2016_q1_newman-weights_kcore.pickle')\n",
    "q2_newman_w = loadfile('./data/2016_q2_newman-weights_kcore.pickle')\n",
    "q1_cci = loadfile('./data/2016_q1_cci-weights_kcore.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nm_cn = loadfile('./data/newman_cn_kcore.pickle')\n",
    "nm_aa = loadfile('./data/newman_adam_kcore.pickle')\n",
    "nm_jc = loadfile('./data/newman_jaccard_kcore.pickle')\n",
    "nm_pa = loadfile('./data/newman_pa_kcore.pickle')\n",
    "cci_cn = loadfile('./data/CII_cn.pickle')\n",
    "cci_aa = loadfile('./data/CII_adam.pickle')\n",
    "cci_jc = loadfile('./data/CII_jaccard.pickle')\n",
    "cci_pa = loadfile('./data/CII_pa.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nm_katz = loadfile('./data/newman_katz_weighted_0_00005.pickle')\n",
    "unweighted_katz = loadfile('./data/newman_katz_unweighted_0_00005.pickle')\n",
    "cci_katz = loadfile('./data/cci_katz_weighted_0_00005.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n2v_p10_q01 = loadfile('./data/node2vec-weighted-p10-q01-100-100.pickle')\n",
    "n2v_p01_q01 = loadfile('./data/node2vec-weighted-p1-q1-100-100.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct dataframe for supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get new core edges\n",
    "nce = list(set(nm_pa.keys()).difference(q1_newman_w.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_scores(edges, score_list):\n",
    "    scores = np.zeros((len(edges), len(score_list)))\n",
    "    for i in range(len(edges)):\n",
    "        for j in range(len(score_list)):\n",
    "            scores[i][j] = score_list[j][edges[i]]\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = combine_scores(nce, [nm_cn, nm_aa, nm_jc, nm_pa, \n",
    "                         cci_cn, cci_aa, cci_jc, cci_pa, \n",
    "                         nm_katz, unweighted_katz, cci_katz,\n",
    "                        n2v_p10_q01, n2v_p01_q01])\n",
    "y = [a in q2_newman_w.keys() for a in nce]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine with user behavior and demographic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_details = loadfile('./data/user_details.pickle')\n",
    "nm_community = loadfile('./data/author_clusters_2016_q1_k25core_newman.pickle')\n",
    "cii_community = loadfile('./data/author_clusters_2016_q1_k25core_cii.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_details.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "26971/(3053**2/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_country = user_details.country_code.to_dict()\n",
    "user_created = user_details.months_since_1970.to_dict()\n",
    "user_commit = user_details.commit_times.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_user_details(edges, detail_list):\n",
    "    details = np.zeros((len(edges), len(detail_list)))\n",
    "    #print (f'{len(edges)/1000}k node pairs to process')\n",
    "    for i in range(len(edges)):\n",
    "        #if not i%10000:\n",
    "        #    print (f'Processing {i/1000}k th node pair')\n",
    "        uid = edges[i][0]\n",
    "        vid = edges[i][1]\n",
    "        details[i][0] = int(detail_list[0][uid] == detail_list[0][vid])\n",
    "        details[i][1] = abs(detail_list[1][uid] - detail_list[1][vid])\n",
    "        details[i][2] = min(detail_list[2][uid], detail_list[2][vid]) == 0\n",
    "        details[i][3] = int(detail_list[3][uid]==detail_list[3][vid])\n",
    "        details[i][4] = int(detail_list[4][uid]==detail_list[4][vid])\n",
    "    return details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "details = get_user_details(nce, [user_country, user_created, user_commit, nm_community, cii_community])\n",
    "X_new = np.concatenate((X, details), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a baseline model with logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Divide data into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=1234, stratify=y)\n",
    "# Downsample the training set\n",
    "rus = RandomUnderSampler()\n",
    "X_under, y_under = rus.fit_sample(X_train, y_train)\n",
    "ssX = StandardScaler()\n",
    "X_scaled = ssX.fit_transform(X_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "          ('logistic', LogisticRegression),\n",
    "          ('tree', DecisionTreeClassifier),\n",
    "          ('forest', RandomForestClassifier),\n",
    "          ('xgboost', XGBClassifier)\n",
    "         ]\n",
    "\n",
    "param_choices = [    \n",
    "    {\n",
    "        'C': np.logspace(-3, 6, 12),\n",
    "        'penalty': ['l1', 'l2']\n",
    "    },\n",
    "    {\n",
    "        'max_depth': [1,2,3,4,5],\n",
    "        'min_samples_leaf': [1,3,5]\n",
    "    },\n",
    "    {\n",
    "        'criterion':['gini','entropy'],\n",
    "        'n_estimators': [40,50,60],\n",
    "        'min_samples_leaf':[1,3],\n",
    "        'min_samples_split':[2,5]\n",
    "    },\n",
    "    {\n",
    "        'max_depth': [3,4,5],\n",
    "        'n_estimators': [1, 50, 100,200],\n",
    "        'objective':['binary:logistic']\n",
    "    }\n",
    "]\n",
    "\n",
    "grids = {}\n",
    "for model_info, params in zip(models, param_choices):\n",
    "    name, model = model_info\n",
    "    grid = GridSearchCV(model(), params, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "    grid.fit(X_scaled, y_under)\n",
    "    s = \"{}: best score: {}\".format(name, grid.best_score_)\n",
    "    print(s)\n",
    "    grids[name] = grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_scaled = ssX.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_pred = [x[1] for x in grids['tree'].predict_proba(X_test_scaled)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check training accuracy with the same method with similarity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_prediction_accuracy(pred_prob, y):\n",
    "    n = sum(y)\n",
    "    sorted_index = [a for a,b in sorted(enumerate(pred_prob), key=lambda x:x[1], reverse=True)][:n]\n",
    "    true_index = [a for a,b in enumerate(y) if b == 1]\n",
    "    matches = set(sorted_index).intersection(true_index)\n",
    "    return len(matches)/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled = ssX.transform(X_train)\n",
    "y_test_pred = [x[1] for x in grids['tree'].predict_proba(X_test_scaled)]\n",
    "for model in grids.keys():\n",
    "    X_train_scaled = ssX.transform(X_train)\n",
    "    y_train_pred = [x[1] for x in grids[model].predict_proba(X_train_scaled)]\n",
    "    print (f'Model {model} has an accuracy of {check_prediction_accuracy(y_train_pred, y_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the best model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_scaled = ssX.transform(X_test)\n",
    "y_test_pred = [x[1] for x in grids['forest'].predict_proba(X_test_scaled)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_prediction_accuracy(y_test_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_importance(model, df, title, columns=None, save=False):\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[-10:]\n",
    "    plt.figure()\n",
    "    plt.axvline(x=1/df.shape[1], color='#1DB954', label='Avg Importance')\n",
    "    plt.title(title, fontsize=25)\n",
    "    plt.barh(range(10), importances[indices], color='#FF5A60', align='center', )\n",
    "    if (columns == None):\n",
    "        plt.yticks(range(10), df.columns[indices])\n",
    "    else:\n",
    "        plt.yticks(range(10), columns)\n",
    "    plt.xlabel('Relative Importance', fontsize=15)\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_name = (['nm_cn', 'nm_aa', 'nm_jc', 'nm_pa', \n",
    "                 'cci_cn', 'cci_aa', 'cci_jc', 'cci_pa', \n",
    "                 'nm_katz', 'unweighted_katz', 'cci_katz',\n",
    "                 'user_country', 'user_created', 'user_commit', \n",
    "                 'nm_community', 'cii_community','n2v_p10_q01', 'n2v_p01_q01'])[::-1]\n",
    "title = 'Feature importance'\n",
    "plot_importance(grids['forest'].best_estimator_, X_scaled, title, columns=columns_name, save=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check if more data would help\n",
    "\n",
    "def drawLearningCurve(model, X, y, ylim_lower = -100, ylim_higher = 100, save=False):\n",
    "    best_clas_fit = model.fit(X, y)\n",
    "    train_sizes, train_scores, test_scores = learning_curve(best_clas_fit, X, y, cv=5)\n",
    "    ave_train_scores = train_scores.mean(axis=1)\n",
    "    ave_test_scores = test_scores.mean(axis=1)\n",
    "\n",
    "    learn_df  = pd.DataFrame({\n",
    "        'train_size': train_sizes,\n",
    "        'train_score': ave_train_scores,\n",
    "        'test_score': ave_test_scores\n",
    "    })\n",
    "\n",
    "    plot_lm_0 = plt.figure(1)\n",
    "    plot_lm_0.set_figheight(6)\n",
    "    plot_lm_0.set_figwidth(12)\n",
    "    plt.plot(learn_df['train_size'], learn_df['train_score'], 'r--o', label='train scores')\n",
    "    plt.plot(learn_df['train_size'], learn_df['test_score'], 'b--x', label='test scores')\n",
    "    plt.legend(loc='lower right', fontsize=20)\n",
    "    plt.xlabel('Training sizes', fontsize=20)\n",
    "    plt.ylabel('Score', fontsize=20)\n",
    "    plt.title('Learning Curve', fontsize=26)\n",
    "    plt.ylim(ylim_lower,ylim_higher)\n",
    "    if (save):\n",
    "        plt.save('./data/img/learning_curve.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawLearningCurve(grids['forest'].best_estimator_, X_scaled, y_under.ravel(), 0.4, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (conda 3.6)",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
